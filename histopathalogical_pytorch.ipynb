{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=mps_device)\n",
        "    print (x)\n",
        "else:\n",
        "    print (\"MPS device not found.\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision pandas python-dotenv kaggle scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m9QIHv3ZeK_J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jjMlvHonnB0O"
      },
      "outputs": [],
      "source": [
        "def download_data_from_kaggle():\n",
        "    \"\"\"\n",
        "    Downloads the dataset from Kaggle and unzips it.\n",
        "    Assumes environment variables KAGGLE_USERNAME and KAGGLE_KEY are set.\n",
        "    \"\"\"\n",
        "    # Colab-specific: only use these if running on Google Colab\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "        os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "    except ImportError:\n",
        "        # load .env\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv()\n",
        "\n",
        "    # Download via Kaggle API\n",
        "    os.system(\"kaggle competitions download -c histopathologic-cancer-detection\")\n",
        "    os.system(\"unzip -nq histopathologic-cancer-detection.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtBvSFDCnRkZ"
      },
      "outputs": [],
      "source": [
        "download_data_from_kaggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4KFG4BDam4bu"
      },
      "outputs": [],
      "source": [
        "train_dir = 'train'\n",
        "test_dir = 'test'\n",
        "csv_path = 'train_labels.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WXQ4iionntJC"
      },
      "outputs": [],
      "source": [
        "# Load labels\n",
        "labels = pd.read_csv(csv_path)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_labels, val_labels = train_test_split(labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "VgjnQKEbn0tn"
      },
      "outputs": [],
      "source": [
        "# import ImageDataset as ImageDataset # on MacOS, import ImageDataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, labels, image_folder, transform=None):\n",
        "        self.labels = labels\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get image path and label\n",
        "        img_name = os.path.join(self.image_folder, self.labels.iloc[idx, 0])\n",
        "        label = self.labels.iloc[idx, 1]\n",
        "\n",
        "        # Open and transform image\n",
        "        image = Image.open(img_name + \".tif\").convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "YsjnWz82Q_Jb"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        \"\"\"\n",
        "        EarlyStopping class to monitor the validation loss and stop if no improvement for 'patience' epochs.\n",
        "\n",
        "        Args:\n",
        "            patience (int): How many epochs to wait after the last time validation loss improved.\n",
        "            delta (float): Minimum change to qualify as an improvement.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.counter = 0\n",
        "        self.best_model_wts = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        \"\"\"\n",
        "        Call method to check if the validation loss improved. If not, increase the counter.\n",
        "\n",
        "        Args:\n",
        "            val_loss (float): The current validation loss.\n",
        "            model (torch.nn.Module): The model being trained.\n",
        "        \"\"\"\n",
        "        score = -val_loss  # We want to minimize the validation loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.best_model_wts = model.state_dict()\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.best_model_wts = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "    def get_best_weights(self):\n",
        "        \"\"\"\n",
        "        Returns the weights of the best model found so far.\n",
        "        \"\"\"\n",
        "        return self.best_model_wts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5W9GXqrn7MO"
      },
      "outputs": [],
      "source": [
        "# Define transformations for normalization, ResNet requires\n",
        "# resizing to at least 224 W and H\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96,96)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "predict_transform = transforms.Compose([\n",
        "    transforms.Resize((96,96)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ImageDataset(train_labels, train_dir, transform=transform)\n",
        "val_dataset = ImageDataset(val_labels, train_dir, transform=predict_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE9b3XDGpsbf"
      },
      "outputs": [],
      "source": [
        "class ConvNet96x96(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(ConvNet96x96, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1) # 96x96x32\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1) # 96x96x64\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1) # 96x96x128\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Reduces each spatial dimension by half\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 24 * 24, 512) # Corrected size\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "        # Dropout (to prevent overfitting)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU and pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers with ReLU and dropout\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = ConvNet96x96()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(model)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SBISbxAtpwI_"
      },
      "outputs": [],
      "source": [
        "# Binary Cross-Entropy Loss for binary classification\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# SGD optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-rw-Pjlp1ht",
        "outputId": "26d2d271-8d3c-45c0-cf0a-2dea872e5d3a"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5, delta=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        print(f\"Batch {i+1}/{len(train_loader)}\", end=\"\\r\")\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Training Loss: {running_loss / len(train_loader)}\")\n",
        "    print(\"Validation:\")\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss += criterion(outputs.squeeze(), labels).item()\n",
        "            predicted = (outputs.squeeze() > 0.5).long()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n",
        "    print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n",
        "    print(f\"Validation Accuracy: {correct / len(val_dataset)}\")\n",
        "\n",
        "    # Early stopping logic\n",
        "    early_stopping(val_loss, model)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_state_dict(early_stopping.get_best_weights())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4lDSKTxp6aE"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), model_name + '.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TSpfhSep77b"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(model_name + '.pth'))\n",
        "model.eval()\n",
        "\n",
        "def predict_image(image_path, model, transform, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    output = model(image).item()\n",
        "    return '1' if output > 0.5 else '0'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1oIjcwk3Qme"
      },
      "outputs": [],
      "source": [
        "# for each image in test dir, predict and produce CSV with results\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "results = []\n",
        "\n",
        "for filename in os.listdir(test_dir):\n",
        "    if filename.endswith('.tif'):\n",
        "        image_path = os.path.join(test_dir, filename)\n",
        "        prediction = predict_image(image_path, model, predict_transform, device)\n",
        "        id_no_ext = os.path.splitext(filename)[0]\n",
        "        results.append({'id': id_no_ext, 'label': prediction})\n",
        "\n",
        "results = pd.DataFrame(results)\n",
        "\n",
        "results.to_csv(model_name + '.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqcUyUz2XlaG"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions submit -c histopathologic-cancer-detection -f {model_name + '.csv'} -m {model_name}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
